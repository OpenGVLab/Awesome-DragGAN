# Awesome-DragGAN ðŸ‰ 

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
[![Awesome Anything](https://img.shields.io/badge/Awesome-Anything-blue)](https://github.com/topics/awesome)


DragGAN has been one of the most popular generative image editing model these days. It provide a brand new way to edit the image by interatively selecting target and source points on the image, giving the greater flexibility to users than existing text-based editing. Though constrainted to generative image manifold currently, the idea of DragGAN should inspired and have inspired a varity of following works. 

Awesome-DragGAN is a curated list of the papers, repositories, tutorials, and anythings related to the DragGAN. 

- [Starting Point](#starting-point)
- [Papers](#papers)
- [Repositories](#repositories)
- [Tutorials](#tutorials)
- [Pretrained GAN Models](#pretrained-gan-models)

> [Contributions](https://github.com//OpenGVLab/Awesome-DragGAN/pulls) are welcome!

## Starting Point [![Star](https://img.shields.io/github/stars/XingangPan/DragGAN.svg?style=social&label=Star)](https://github.com/XingangPan/DragGAN)

> [Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold](https://arxiv.org/abs/2305.10973)
> </br>
> Xingang Pan, Ayush Tewari, Thomas LeimkÃ¼hler, Lingjie Liu, Abhimitra Meka, Christian Theobalt
> </br>
> [[`Code`](https://github.com/XingangPan/DragGAN)]  [[`Project Page`](https://vcai.mpi-inf.mpg.de/projects/DragGAN/)]  [[`Official Implementation`](https://github.com/XingangPan/DragGAN)]


## Papers

[DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing](https://arxiv.org/abs//2306.14435)
</br>
Yujun Shi, Chuhui Xue, Jiachun Pan, Wenqing Zhang, Vincent Y. F. Tan, Song Bai
</br>
[[`Project Page`](https://yujun-shi.github.io/projects/dragdiffusion.html)]
</br>
June 26 2023


## Repositories

-  [DragGAN](https://github.com/OpenGVLab/DragGAN): Unoffficial Implementation by OpenGVLab. [![Star](https://img.shields.io/github/stars/OpenGVLab/DragGAN.svg?style=social&label=Star)](https://github.com/OpenGVLab/DragGAN)
-  [DragGAN](https://github.com/skimai/DragGAN): Unoffficial Implementation by Skim AI Technologies, with a streamlit interface. [![Star](https://img.shields.io/github/stars/skimai/DragGAN.svg?style=social&label=Star)](https://github.com/skimai/DragGAN)
-  [Drag3D](https://github.com/ashawkey/Drag3D): DragGAN meets GET3D for interactive mesh generation and editing. [![Star](https://img.shields.io/github/stars/ashawkey/Drag3D.svg?style=social&label=Star)](https://github.com/ashawkey/Drag3D)
- [DragGAN-Windows-GUI](https://github.com/zhaoyun0071/DragGAN-Windows-GUI): Packaged DragGAN Installtion for Windows.  [![Star](https://img.shields.io/github/stars/zhaoyun0071/DragGAN-Windows-GUI.svg?style=social&label=Star)](https://github.com/zhaoyun0071/DragGAN-Windows-GUI)


## Tutorials

- [How DragGAN Works: A Technical Deep Dive](https://chenliu-1996.github.io/blogs/ExplainDragGAN/main.pdf)
- [DragGAN: Early Access and Local Deployment Tutorial](https://zeqiang-lai.github.io/blog/posts/ai/drag_gan/)

## Pretrained GAN Models

- [Stylegan2](https://github.com/NVlabs/stylegan2): Car, Cat, Church, Human Face, Horse
- [StyleGAN2-Ada](https://github.com/NVlabs/stylegan2-ada-pytorch): Cat, Dog, Wild, Human Face, Painting Face, Brecahad
- [StyleGAN-Human](https://github.com/stylegan-human/StyleGAN-Human): Human
- [Self-Distilled-StyleGAN](https://github.com/self-distilled-stylegan/self-distilled-internet-photos): Bicycle, Dog, Elephant, Giraffe, Horse, Lion, Parrot
